{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7228d156-ccfd-4872-a523-bf4cb593da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "# pip install google-ai-generativelanguage==0.6.15\n",
    "# pip install -qU google-generativeai==0.8.5\n",
    "#pip install langgraph langchain langchain-google-genai openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44484c8f-1353-491b-b4fe-16527f48ae13",
   "metadata": {},
   "source": [
    "### step 1: Import and secure API key input ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abc2468-2cd7-4f11-b4e4-683098f544d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langgraph.graph import StateGraph ,END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012e00b-576e-4296-9cbe-63d2934e0e36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### step 2:  Gemini API key input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41ee321-8f30-43f0-99fc-1abcf1219d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Gemini API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "# API_KEY = \"Your API KEY\"\n",
    "os.environ['GOOGLE_API_KEY'] = getpass.getpass(\"Enter the Gemini API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b4542-5b3b-4495-8eb8-5483bb77d26b",
   "metadata": {},
   "source": [
    "### step 2:  Initialize Gemini 1.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce0c402-dc3d-4208-8c06-1f2354800227",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = \"models/gemini-1.5-flash\",temperature =0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630bda4-6bcd-4a43-926d-84f0c292bbb9",
   "metadata": {},
   "source": [
    "### step 3:  Node to ask user for symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa19ffae-9d08-4405-aa60-cb4554b3adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '-> dict' : This is a type hint that tells us what the function will return.\n",
    "\n",
    "# It means:\n",
    "# \"This function will return a dict (dictionary).\"\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_symptom(state:dict) -> dict:\n",
    "    symptom = input(\"welcome to XYZ hospital,please enter your symptom: \")\n",
    "    state['symptom'] = symptom\n",
    "    return state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fc43424-a35d-44c8-8cbb-8c09bc1c5050",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "### step 4: Node to classify the symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62cdfca1-33f8-4af0-bce1-34588d6c293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "welcome to XYZ hospital,please enter your symptom:  i have fever\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM classifies the symptom as :General\n",
      "final output \n",
      "\n",
      " 'i have fever': seems general: directing you to general ward for consulting a doctor.\n"
     ]
    }
   ],
   "source": [
    "def classify_symptom(state: dict)->dict:\n",
    "    prompt = (\n",
    "        \"you are a helpful medical Assistant, Classify the symptoms below into on of the categories \\n\"\n",
    "        \"-General\\n -Emergency \\n -mental health \\n\"\n",
    "        f\" Symptom :{state['symptom']} \\n\"\n",
    "        \"Respond only with one word : General, Emergency Or Mental Health\"\n",
    "        \"#Example : input : I have fever, Output : General\")\n",
    "        \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    category = response.content.strip()\n",
    "    print(f\"LLM classifies the symptom as :{category}\") #debug\n",
    "    state['category'] = category\n",
    "    return state\n",
    "\n",
    "### step 5: Router logic to route to the correct node\n",
    "\n",
    "def symptom_router(state:dict)->dict:\n",
    "    cat = state['category'].lower() \n",
    "    if \"general\" in cat:\n",
    "        return \"general\"\n",
    "    elif \"emergency\" in cat:\n",
    "        return \"emergency\"\n",
    "    elif \"mental\" in cat:\n",
    "        return \"mental_health\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "### step 6: Category-specific response nodes\n",
    "\n",
    "def general_node(state: dict) -> dict:\n",
    "    state['answer'] = f\" '{state['symptom']}': seems general: directing you to general ward for consulting a doctor.\"\n",
    "    return state\n",
    "\n",
    "def emergency_node(state:dict) ->dict:\n",
    "    state['answer'] = f\" '{state['symptom']}': it is a medical Emergency: seeking immediate help.\"\n",
    "    return state\n",
    "\n",
    "def mental_health_node(state:dict) ->dict:\n",
    "    state['answer'] = f\" '{state['symptom']}': seems like a medical health issue: talk to our counseller.\"\n",
    "    return state\n",
    "\n",
    "### step 7: Build langGraph\n",
    "\n",
    "builder = StateGraph(dict)\n",
    "\n",
    "builder.set_entry_point(\"get_symptom\")\n",
    "builder.add_node(\"get_symptom\",get_symptom)\n",
    "builder.add_node(\"classify\",classify_symptom)\n",
    "builder.add_node(\"general\",general_node)\n",
    "builder.add_node(\"emergency\",emergency_node)\n",
    "builder.add_node(\"mental_health\",mental_health_node)\n",
    "\n",
    "\n",
    "builder.add_edge(\"get_symptom\",\"classify\")\n",
    "builder.add_conditional_edges('classify',symptom_router,{\n",
    "    \"general\" : \"general\",\n",
    "    \"emergency\" : \"emergency\",\n",
    "    \"mental_health\" : \"mental_health\"\n",
    "    \n",
    "})\n",
    "\n",
    "builder.add_edge(\"general\",END)\n",
    "builder.add_edge(\"emergency\",END)\n",
    "builder.add_edge(\"mental_health\",END)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Step 8: Compile and invoke the graph\n",
    "\n",
    "graph = builder.compile()\n",
    "final_state = graph.invoke({})\n",
    "\n",
    "print(\"final output \\n\")\n",
    "print(final_state['answer'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3a035-b456-4a21-966e-03c34b9493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c6c8f-5fc3-4dd0-a701-7e22cb6b0878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
